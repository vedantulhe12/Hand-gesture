{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hand module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
    "\n",
    "# List of classes\n",
    "classes = [\"call\", \"dislike\", \"Fist\", \"four\", \"like\", \"one\", \"peace\", \"rock\", \"stop\", \"three\", \"two up\"]\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "image_files = []\n",
    "labels = []\n",
    "\n",
    "# Define target image size\n",
    "target_size = (150, 150)\n",
    "\n",
    "# Specify the full path to the 'Gesture sense' folder\n",
    "base_folder = r\"C:\\Users\\HP\\Contacts\\Desktop\\Gesture sense\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each class folder\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(base_folder, \"Data\", class_name)\n",
    "    # Check if the class folder exists\n",
    "    if not os.path.exists(class_folder):\n",
    "        print(f\"Class folder '{class_name}' does not exist.\")\n",
    "        continue\n",
    "    # Loop through the files in the class folder\n",
    "    for filename in os.listdir(class_folder):\n",
    "        if filename.endswith(\".jpg\"):  # Check if the file has the '.jpg' extension\n",
    "            filepath = os.path.join(class_folder, filename)\n",
    "            print(\"Loading image:\", filepath)  # Debug statement to check the loaded file path\n",
    "            # Load image using OpenCV\n",
    "            image = cv2.imread(filepath)\n",
    "            if image is not None:  # Check if the image is loaded successfully\n",
    "                print(\"Image loaded successfully\")  # Debug statement\n",
    "                # Resize the image to the target size\n",
    "                image = cv2.resize(image, target_size)\n",
    "                # Append image and label\n",
    "                image_files.append(image)\n",
    "                labels.append(class_name)\n",
    "            else:\n",
    "                print(f\"Failed to load image: {filename}\")\n",
    "        else:\n",
    "            print(f\"Skipping non-image file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "data = np.array(image_files)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are samples in the dataset\n",
    "if len(data) == 0:\n",
    "    print(\"No images loaded.\")\n",
    "else:\n",
    "    # Now you have your resized image data and corresponding class labels ready for further processing\n",
    "    print(\"Data shape:\", data.shape)\n",
    "    print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Split data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize empty lists for hand landmarks and labels\n",
    "    hand_landmarks = []\n",
    "    hand_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Loop through the training data to detect hand landmarks using MediaPipe\n",
    "    for image in x_train:\n",
    "        # Convert image to RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Detect hand landmarks\n",
    "        results = hands.process(image_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmark in results.multi_hand_landmarks:\n",
    "                # Extract hand landmarks and corresponding label\n",
    "                landmark_list = [(lm.x, lm.y, lm.z) for lm in hand_landmark.landmark]  # Extract x, y, z coordinates\n",
    "                hand_landmarks.append(landmark_list)\n",
    "                hand_labels.append(y_train[len(hand_landmarks) - 1])  # Corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hand landmarks to numpy array\n",
    "    x_train_hand_landmarks = np.array(hand_landmarks)\n",
    "    y_train_hand_labels = np.array(hand_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Flatten the hand landmarks\n",
    "    x_train_flat = x_train_hand_landmarks.reshape(x_train_hand_landmarks.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize the Random Forest classifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "    model.fit(x_train_flat, y_train_hand_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Specify the directory path where you want to save the model\n",
    "    model_directory = r\"C:\\Users\\HP\\Contacts\\Desktop\\Gesture sense\\Model\"\n",
    "\n",
    "    # Specify the filename for the model\n",
    "    model_filename = \"hand_gesture_model_mediapipe.pkl\"\n",
    "\n",
    "    # Combine the directory path and filename\n",
    "    model_filepath = os.path.join(model_directory, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to the file\n",
    "    with open(model_filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(\"Model saved as:\", model_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
