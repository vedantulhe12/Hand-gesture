{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Import OpenCV library for image processing\n",
    "from cvzone.HandTrackingModule import HandDetector  # Import HandDetector from cvzone library for hand tracking\n",
    "from cvzone.ClassificationModule import Classifier  # Import Classifier from cvzone library for gesture classification\n",
    "import numpy as np  # Import NumPy library for numerical operations\n",
    "import math  # Import math library for mathematical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture from default webcam and create HandDetector object with maxHands set to 2\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and labels for gesture classification\n",
    "classifier = Classifier(\"Model/keras_model.h5\", \"Model/labels.txt\")\n",
    "\n",
    "# Define variables for cropping and saving images\n",
    "offset = 20  # Offset for cropping hand regions\n",
    "imgSize = 300  # Desired size for cropped images\n",
    "folder = \"Data\"  # Folder path to save images\n",
    "labels = [\"like\", \"dislike\", \"Fist\", \"one\", \"two up\", \"three\", \"four\", \"rock\", \"peace\", \"stop\", \"call\"]  # List of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop to capture and process webcam feed\n",
    "while True:\n",
    "    # Read a frame from the webcam feed\n",
    "    success, img = cap.read()\n",
    "    imgOutput = img.copy()  # Create a copy of the original frame for drawing results\n",
    "    \n",
    "    # Detect hands in the frame\n",
    "    hands, img = detector.findHands(img)\n",
    "    \n",
    "    # If hands are detected, process them\n",
    "    if hands:\n",
    "        hand = hands[0]  # Get information about the first detected hand\n",
    "        x, y, w, h = hand['bbox']  # Extract bounding box coordinates\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255  # Create white background image\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]  # Crop hand region from the frame\n",
    "        \n",
    "        # If cropped image is not empty, resize and classify it\n",
    "        if imgCrop.size != 0:\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)  # Perform gesture classification\n",
    "            \n",
    "            # Draw results on the output frame\n",
    "            cv2.rectangle(imgOutput, (x - offset, y - offset - 50), (x - offset + 90, y - offset - 50 + 50), (255, 0, 255), cv2.FILLED)\n",
    "            cv2.putText(imgOutput, labels[index], (x, y - 26), cv2.FONT_HERSHEY_COMPLEX, 1.7, (255, 255, 255), 2)\n",
    "            cv2.rectangle(imgOutput, (x - offset, y - offset), (x + w + offset, y + h + offset), (255, 0, 255), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the output frame with drawn results\n",
    "    cv2.imshow(\"Image\", imgOutput)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
